{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89ddc849",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "\n",
    "# Defina o caminho para o seu arquivo CSV\n",
    "input_csv_path = './data/data.csv'\n",
    "# Defina o caminho de saída para o arquivo JSON processado\n",
    "output_json_path = './data/top_products.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db4b846",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "918b4c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando o carregamento de dados de: ./data/data.csv\n",
      "Processando chunk 1...\n",
      "Processando chunk 2...\n",
      "Processando chunk 3...\n",
      "Processando chunk 4...\n",
      "Processando chunk 5...\n",
      "Processando chunk 6...\n",
      "Processando chunk 7...\n",
      "Processando chunk 8...\n",
      "Processando chunk 9...\n",
      "Processando chunk 10...\n",
      "Processando chunk 11...\n",
      "Processando chunk 12...\n",
      "Processando chunk 13...\n",
      "Processando chunk 14...\n",
      "Processando chunk 15...\n",
      "Processando chunk 16...\n",
      "Processando chunk 17...\n",
      "Processando chunk 18...\n",
      "Processando chunk 19...\n",
      "Processando chunk 20...\n",
      "Processando chunk 21...\n",
      "Processando chunk 22...\n",
      "Processando chunk 23...\n",
      "Processando chunk 24...\n",
      "Processando chunk 25...\n",
      "Processando chunk 26...\n",
      "Dados carregados com sucesso. Iniciando o processamento...\n",
      "Processamento concluído.\n",
      "Dados processados exportados para: ./data/top_products.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def process_sales_data(csv_path, num_top_products=20):\n",
    "    \"\"\"\n",
    "    Processa o CSV de vendas para identificar os principais produtos.\n",
    "\n",
    "    Args:\n",
    "        csv_path (str): Caminho para o arquivo CSV de entrada.\n",
    "        num_top_products (int): Número de produtos principais a serem extraídos.\n",
    "\n",
    "    Returns:\n",
    "        list: Uma lista de dicionários contendo os dados dos principais produtos.\n",
    "    \"\"\"\n",
    "    print(f\"Iniciando o carregamento de dados de: {csv_path}\")\n",
    "    try:\n",
    "        # Carrega o CSV. Use 'sep=;' pois seus dados são separados por ponto e vírgula.\n",
    "        # chunksize é usado para ler o arquivo em pedaços, economizando memória.\n",
    "        chunks = pd.read_csv(csv_path, sep=';', chunksize=100000, encoding='utf-8')\n",
    "\n",
    "        all_data = pd.DataFrame()\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            print(f\"Processando chunk {i+1}...\")\n",
    "            all_data = pd.concat([all_data, chunk], ignore_index=True)\n",
    "\n",
    "        print(\"Dados carregados com sucesso. Iniciando o processamento...\")\n",
    "\n",
    "        # Garante que as colunas numéricas são do tipo correto\n",
    "        all_data['TotalItem'] = pd.to_numeric(all_data['TotalItem'], errors='coerce')\n",
    "        all_data['Controle'] = pd.to_numeric(all_data['Controle'], errors='coerce') # Para contar a incidência de vendas\n",
    "\n",
    "        # Agrupar por produto para calcular o total de vendas (TotalItem)\n",
    "        # e a contagem de vendas únicas (Controle)\n",
    "        product_summary = all_data.groupby('ProNom').agg(\n",
    "            total_vendas=('TotalItem', 'sum'),\n",
    "            incidencia_vendas=('Controle', lambda x: x.nunique()) # Contar vendas únicas\n",
    "        ).reset_index()\n",
    "\n",
    "        # Calcular a porcentagem de incidência em vendas\n",
    "        total_unique_sales = all_data['Controle'].nunique()\n",
    "        product_summary['percent_incidencia'] = (product_summary['incidencia_vendas'] / total_unique_sales) * 100\n",
    "\n",
    "        # Ordenar por total_vendas para pegar os principais produtos\n",
    "        top_products = product_summary.sort_values(by='total_vendas', ascending=False).head(num_top_products)\n",
    "\n",
    "        # Converter para o formato de lista de dicionários\n",
    "        output_data = top_products.to_dict(orient='records')\n",
    "\n",
    "        print(\"Processamento concluído.\")\n",
    "        return output_data\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Erro: O arquivo '{csv_path}' não foi encontrado.\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"Ocorreu um erro durante o processamento: {e}\")\n",
    "        return []\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    processed_data = process_sales_data(input_csv_path)\n",
    "\n",
    "    if processed_data:\n",
    "        with open(output_json_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(processed_data, f, ensure_ascii=False, indent=4)\n",
    "        print(f\"Dados processados exportados para: {output_json_path}\")\n",
    "    else:\n",
    "        print(\"Nenhum dado processado para exportar.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
